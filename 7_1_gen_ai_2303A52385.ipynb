{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2UVNX5aZimKYIJjh6btZX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amma-Anjali/Generative_AI_2025/blob/main/7_1_gen_ai_2303A52385.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLGNMKmexyny"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adadelta\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Load Dataset\n",
        "dataset_url = \"https://drive.google.com/uc?id=1AcdENlVm5dccNyo_vgdMbneX8YVvH5R3\"\n",
        "df = pd.read_csv(dataset_url)\n",
        "\n",
        "# Print Data Info\n",
        "print(\"Dataset Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nSample Data:\")\n",
        "print(df.head())\n",
        "\n",
        "# Identify categorical columns\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "print(\"\\nCategorical Columns:\", list(categorical_cols))\n",
        "\n",
        "# Convert categorical columns to numeric using LabelEncoder\n",
        "label_encoders = {}  # Store encoders for future use\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])  # Convert categories to numbers\n",
        "    label_encoders[col] = le  # Save encoder for deployment\n",
        "\n",
        "# Separate features and target\n",
        "label_encoders[col] = le  # Save encoder for deployment\n",
        "# Separate features and target\n",
        "y = df.iloc[:, -1].values  # Last column as target (Diabetes Diagnosis)\n",
        "X = df.iloc[:, :-1].values  # All other columns as features\n",
        "\n",
        "# Normalize Features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split dataset into Training and Testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build ANN Model\n",
        "model = Sequential([\n",
        "    Dense(8, activation='relu', input_shape=(X_train.shape[1],)),  # Hidden Layer 1\n",
        "    Dense(16, activation='relu'),  # Hidden Layer 2\n",
        "    Dense(20, activation='relu'),  # Hidden Layer 3\n",
        "    Dense(10, activation='relu'),  # Hidden Layer 4\n",
        "    Dense(1, activation='sigmoid')  # Output Layer for binary classification\n",
        "])\n",
        "\n",
        "# Compile Model\n",
        "model.compile(optimizer=Adadelta(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train Model\n",
        "model.fit(X_train, y_train, epochs=150, batch_size=64, validation_data=(X_test, y_test), verbose=1)\n",
        "\n",
        "# Save Model\n",
        "model.save(\"diabetes_ann_model.h5\")\n",
        "\n",
        "# Predict on Training and Test Data\n",
        "y_pred_train = (model.predict(X_train) > 0.5).astype(int)\n",
        "y_pred_test = (model.predict(X_test) > 0.5).astype(int)\n",
        "\n",
        "# Calculate Performance Metrics\n",
        "train_acc = accuracy_score(y_train, y_pred_train)\n",
        "test_acc = accuracy_score(y_test, y_pred_test)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_test)\n",
        "report = classification_report(y_test, y_pred_test)\n",
        "\n",
        "# Display Results\n",
        "print(f\"\\nTraining Accuracy: {train_acc:.4f}\")\n",
        "print(f\"Testing Accuracy: {test_acc:.4f}\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(report)\n",
        "\n",
        "# Load the Model for Deployment\n",
        "loaded_model = keras.models.load_model(\"diabetes_ann_model.h5\")\n",
        "\n",
        "# Function to Predict Diabetes\n",
        "def predict_diabetes(input_data):\n",
        "    \"\"\"\n",
        "    This function takes a raw input data row, processes it, and predicts diabetes.\n",
        "    \"\"\"\n",
        "    # Ensure input data is a 2D array\n",
        "    input_data = np.array(input_data).reshape(1, -1)\n",
        "\n",
        "    # Apply Standard Scaling\n",
        "    input_scaled = scaler.transform(input_data)\n",
        "# Make Prediction\n",
        "    prediction = loaded_model.predict(input_scaled)[0, 0]\n",
        "\n",
        "    return \"Diabetic\" if prediction > 0.5 else \"Non-Diabetic\"\n",
        "\n",
        "# Example Prediction\n",
        "sample_patient = X_test[0]  # Get a sample from test data\n",
        "prediction_result = predict_diabetes(sample_patient)\n",
        "print(f\"\\nPredicted Diagnosis: {prediction_result}\")"
      ]
    }
  ]
}