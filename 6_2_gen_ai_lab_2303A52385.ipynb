{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0iOVydykakeL11gog+1N7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amma-Anjali/Generative_AI_2025/blob/main/6_2_gen_ai_lab_2303A52385.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvmsbVVJwEXy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=1AcdENlVm5dccNyo_vgdMbneX8YVvH5R3'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "target_column = 'Price' if 'Price' in df.columns else 'price' if 'price' in df.columns else None\n",
        "if target_column is None:\n",
        "    raise KeyError(\"Target column not found. Check dataset column names.\")\n",
        "\n",
        "X = df.drop(columns=[target_column])\n",
        "y = df[target_column]\n",
        "\n",
        "categorical_columns = X.select_dtypes(include=['object']).columns\n",
        "X = pd.get_dummies(X, columns=categorical_columns, drop_first=True)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model = Sequential([\n",
        "    Input(shape=(X_train.shape[1],)),\n",
        "    Dense(15, activation='relu'),\n",
        "    Dense(20, activation='relu'),\n",
        "    Dense(25, activation='relu'),\n",
        "    Dense(20, activation='relu'),\n",
        "    Dense(15, activation='relu'),\n",
        "    Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics=['mae'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=150, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "train_mae = model.evaluate(X_train, y_train, verbose=0)[1]\n",
        "test_mae = model.evaluate(X_test, y_test, verbose=0)[1]\n",
        "print(f'Training MAE: {train_mae}, Testing MAE: {test_mae}')\n",
        "\n",
        "model.save('housing_price_model.h5')\n",
        "\n",
        "plt.plot(history.history['mae'])\n",
        "plt.plot(history.history['val_mae'])\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MAE')\n",
        "plt.legend(['Train MAE', 'Test MAE'])\n",
        "plt.show()\n",
        "\n",
        "def predict_price(features):\n",
        "    loaded_model = keras.models.load_model('housing_price_model.h5')\n",
        "    features = scaler.transform([features])\n",
        "    return loaded_model.predict(features)[0][0]"
      ]
    }
  ]
}